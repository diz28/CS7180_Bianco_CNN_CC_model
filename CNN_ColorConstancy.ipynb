{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bianco's CNN color constancy model recreated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CS 7180 - Advanced Perception\n",
    "#### Di Zhang & Prakriti Pritmani\n",
    "#### Oct 14, 2023"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## imported packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import scipy.io\n",
    "import glob\n",
    "from random import randint\n",
    "import progressbar as pb\n",
    "import h5py\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "from keras import layers, optimizers\n",
    "from keras.layers import Input, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D\n",
    "from keras.layers import AveragePooling2D, MaxPooling2D, Dropout, GlobalMaxPooling2D, GlobalAveragePooling2D\n",
    "from keras.models import Model\n",
    "from keras.initializers import glorot_uniform\n",
    "from keras import backend as K\n",
    "from keras.preprocessing import image\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define progress timer class\n",
    "class progress_timer:\n",
    "\n",
    "    def __init__(self, n_iter, description=\"Something\"):\n",
    "        self.n_iter         = n_iter\n",
    "        self.iter           = 0\n",
    "        self.description    = description + ': '\n",
    "        self.timer          = None\n",
    "        self.initialize()\n",
    "\n",
    "    def initialize(self):\n",
    "        #initialize timer\n",
    "        widgets = [self.description, pb.Percentage(), ' ',   \n",
    "                   pb.Bar('=', '[', ']'), ' ', pb.ETA()]\n",
    "        self.timer = pb.ProgressBar(widgets=widgets, maxval=self.n_iter).start()\n",
    "\n",
    "    def update(self, q=1):\n",
    "        #update timer\n",
    "        self.timer.update(self.iter)\n",
    "        self.iter += q\n",
    "\n",
    "    def finish(self):\n",
    "        #end timer\n",
    "        self.timer.finish()\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocesssing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path_mat = '/Users/dizhang/Desktop/NEU/CS7180_Advanced_Perception/assignment/CS7180_Bianco_CNN_CC_model/NikonD40_gt.mat'\n",
    "# path = '/Users/dizhang/Desktop/NEU/CS7180_Advanced_Perception/assignment/CS7180_Bianco_CNN_CC_model/RAW/'\n",
    "# gt_mat = scipy.io.loadmat(path_mat, squeeze_me = True, struct_as_record = False)\n",
    "# gt_illum = gt_mat['groundtruth_illuminants'][:5][1]\n",
    "# print(gt_illum)\n",
    "\n",
    "# flist = glob.glob(path + '*.NEF')\n",
    "\n",
    "# print(flist)\n",
    "\n",
    "# image_number = flist[0];\n",
    "# index = (image_number.replace(path ,'')).replace('.NEF', '').replace('NikonD40_', '');\n",
    "\n",
    "\n",
    "# print(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data(train_size, patch_size):\n",
    "\n",
    "    mat_path = '/Users/dizhang/Desktop/NEU/CS7180_Advanced_Perception/assignment/CS7180_Bianco_CNN_CC_model/NikonD40_gt.mat'\n",
    "    path = '/Users/dizhang/Desktop/NEU/CS7180_Advanced_Perception/assignment/CS7180_Bianco_CNN_CC_model/RAW_train/'\n",
    "\n",
    "    illum_mat = scipy.io.loadmat(mat_path, squeeze_me = True, struct_as_record = False)\n",
    "    ground_truth_illum = illum_mat['groundtruth_illuminants']\n",
    "    \n",
    "    flist = glob.glob(path + '*.NEF')\n",
    "    number_of_gt = len(flist)\n",
    "    \n",
    "    pt = progress_timer(n_iter = number_of_gt, description = 'Generating Training Data :')\n",
    "    \n",
    "    patches_per_image = int(train_size/number_of_gt)\n",
    "\n",
    "    X_origin, Y_origin, name_train = [], [], []\n",
    "    i = 0\n",
    "    patch_r, patch_c = patch_size\n",
    "\n",
    "    while (i < number_of_gt):\n",
    "        \n",
    "        image_number = flist[i]\n",
    "        index = (image_number.replace(path ,'')).replace('.NEF', '').replace('NikonD40_', '')\n",
    "        \n",
    "        image = cv2.imread(image_number)\n",
    "        n_r, n_c, _ = np.shape(image)\n",
    "        total_patch = int(((n_r - n_r%patch_r)/patch_r)*((n_c - n_c%patch_c)/patch_c))\n",
    "        \n",
    "        img_resize = cv2.resize(image, ((n_r - n_r%patch_r), (n_c - n_c%patch_c)))\n",
    "        img_reshape = np.reshape(img_resize, (int(patch_r), -1, 3))\n",
    "        \n",
    "        #Create CLAHE object\n",
    "        clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "    \n",
    "        for j in range (0, patches_per_image):\n",
    "            \n",
    "            rd = randint(0, total_patch - 1)\n",
    "            img_patch = img_reshape[0:patch_r, rd*patch_c:(rd+1)*patch_c]\n",
    "            \n",
    "            #Convert image to Lab to perform contrast normalizing\n",
    "            lab= cv2.cvtColor(img_patch, cv2.COLOR_BGR2LAB)\n",
    "            \n",
    "            #Contrast normalizing(Stretching)\n",
    "            l, a, b = cv2.split(lab)\n",
    "            cl = clahe.apply(l)\n",
    "            clab = cv2.merge((cl, a, b))\n",
    "            \n",
    "            #Convert back to BGR\n",
    "            img_patch = cv2.cvtColor(clab, cv2.COLOR_LAB2BGR)\n",
    "            \n",
    "            img_patch = cv2.cvtColor(img_patch, cv2.COLOR_BGR2RGB)\n",
    "            \n",
    "            X_origin.append(img_patch)\n",
    "            Y_origin.append(ground_truth_illum[int(index) - 1])\n",
    "        \n",
    "        name_train.append('%04d' % (int(index) - 1))\n",
    "             \n",
    "        i += 1\n",
    "        \n",
    "        pt.update()\n",
    " \n",
    "    X_origin = np.asarray(X_origin)\n",
    "    Y_origin = np.asarray(Y_origin)\n",
    "    \n",
    "    X_origin = X_origin/255\n",
    "    max_Y = np.amax(Y_origin, 1)\n",
    "    Y_origin[:, 0] = Y_origin[:, 0]/max_Y\n",
    "    Y_origin[:, 1] = Y_origin[:, 1]/max_Y\n",
    "    Y_origin[:, 2] = Y_origin[:, 2]/max_Y\n",
    "    \n",
    "    seed = randint(1, 5000)\n",
    "    np.random.seed(seed)\n",
    "    X_origin = np.random.permutation(X_origin)\n",
    "    \n",
    "    np.random.seed(seed)\n",
    "    Y_origin = np.random.permutation(Y_origin)\n",
    "    \n",
    "    pt.finish()\n",
    "    \n",
    "    return X_origin, Y_origin, name_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Training Data :: 100% [==============================] Time: 0:00:00\n"
     ]
    }
   ],
   "source": [
    "train_size = 1600\n",
    "patch_size = (32, 32)\n",
    "\n",
    "X_train, Y_train, name_train = generate_data(train_size, patch_size)\n",
    "np.save('X_train.npy', X_train)\n",
    "np.save('Y_train.npy', Y_train) \n",
    "np.save('name_train.npy', name_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Training Data :: 100% [==============================] Time: 0:00:00\n"
     ]
    }
   ],
   "source": [
    "test_size = 740\n",
    "patch_size = (32, 32)\n",
    "\n",
    "X_test, Y_test, name_test = generate_data(test_size, patch_size)\n",
    "np.save('X_test.npy', X_test)\n",
    "np.save('Y_test.npy', Y_test) \n",
    "np.save('Y_test.npy', name_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "720\n"
     ]
    }
   ],
   "source": [
    "print(len(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ColorNet(input_shape, channels = 3):\n",
    "    \n",
    "    # Define the input as a tensor with shape input_shape\n",
    "    X_input = Input(input_shape)\n",
    "\n",
    "    # Stage 1\n",
    "    X = Conv2D(240, (1, 1), strides = (1, 1), name = 'conv1', kernel_initializer = glorot_uniform(seed=0))(X_input)\n",
    "    X = BatchNormalization(name = 'bn_conv1')(X)\n",
    "    \n",
    "    X = MaxPooling2D((8, 8), strides=(8, 8))(X)\n",
    "  \n",
    "    # output layer\n",
    "    X = Flatten()(X)\n",
    "    X = Dense(40, activation='relu', name='fc' + str(40))(X);\n",
    "    X = Dropout(rate = 0.5)(X);\n",
    "    \n",
    "    X = Dense(channels, activation=None, name='fc' + str(channels))(X);\n",
    "    \n",
    "    # Create model\n",
    "    color_model = Model(inputs = X_input, outputs = X, name='ColorNet');\n",
    "    \n",
    "    return color_model;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "7/7 [==============================] - 1s 117ms/step - loss: -0.6129 - accuracy: 0.4841 - val_loss: -0.9817 - val_accuracy: 0.9813\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 1s 100ms/step - loss: -0.9030 - accuracy: 0.6689 - val_loss: -0.9831 - val_accuracy: 0.9813\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 1s 100ms/step - loss: -0.9108 - accuracy: 0.7486 - val_loss: -0.9801 - val_accuracy: 0.9813\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 1s 100ms/step - loss: -0.9246 - accuracy: 0.7777 - val_loss: -0.9809 - val_accuracy: 0.9813\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 1s 99ms/step - loss: -0.9339 - accuracy: 0.7758 - val_loss: -0.9839 - val_accuracy: 0.9813\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 1s 107ms/step - loss: -0.9365 - accuracy: 0.7992 - val_loss: -0.9860 - val_accuracy: 0.9813\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 1s 104ms/step - loss: -0.9412 - accuracy: 0.7917 - val_loss: -0.9865 - val_accuracy: 0.9813\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 1s 100ms/step - loss: -0.9454 - accuracy: 0.7739 - val_loss: -0.9839 - val_accuracy: 0.9813\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 1s 100ms/step - loss: -0.9535 - accuracy: 0.8602 - val_loss: -0.9827 - val_accuracy: 0.9813\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 1s 98ms/step - loss: -0.9595 - accuracy: 0.8856 - val_loss: -0.9854 - val_accuracy: 0.9813\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 1s 98ms/step - loss: -0.9608 - accuracy: 0.8602 - val_loss: -0.9871 - val_accuracy: 0.9813\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 1s 100ms/step - loss: -0.9642 - accuracy: 0.8583 - val_loss: -0.9868 - val_accuracy: 0.9813\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 1s 101ms/step - loss: -0.9672 - accuracy: 0.8865 - val_loss: -0.9866 - val_accuracy: 0.9813\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 1s 98ms/step - loss: -0.9687 - accuracy: 0.8977 - val_loss: -0.9879 - val_accuracy: 0.9813\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 1s 99ms/step - loss: -0.9703 - accuracy: 0.8884 - val_loss: -0.9884 - val_accuracy: 0.9813\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 1s 100ms/step - loss: -0.9731 - accuracy: 0.9034 - val_loss: -0.9881 - val_accuracy: 0.9813\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - 1s 100ms/step - loss: -0.9763 - accuracy: 0.9146 - val_loss: -0.9878 - val_accuracy: 0.9813\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - 1s 103ms/step - loss: -0.9740 - accuracy: 0.9174 - val_loss: -0.9889 - val_accuracy: 0.9813\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - 1s 100ms/step - loss: -0.9768 - accuracy: 0.9165 - val_loss: -0.9893 - val_accuracy: 0.9813\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - 1s 100ms/step - loss: -0.9753 - accuracy: 0.9259 - val_loss: -0.9887 - val_accuracy: 0.9813\n",
      "23/23 [==============================] - 0s 4ms/step - loss: -0.9882 - accuracy: 0.9750\n",
      "\n",
      "Loss = -0.9882034063339233\n",
      "Test Accuracy = 0.9750000238418579\n",
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "loss_cos_sim = tf.keras.losses.CosineSimilarity()\n",
    "rmsprop = optimizers.legacy.RMSprop(lr = 0.001, rho=0.9, epsilon=None, decay=0.0);\n",
    "\n",
    "cc_model = ColorNet(input_shape = X_train.shape[1:4]);\n",
    "cc_model.compile(optimizer = 'Adam', loss = loss_cos_sim , metrics = ['accuracy']);\n",
    "\n",
    "estimate = cc_model.fit(X_train, Y_train, validation_split = 0.3333, epochs = 20, batch_size = 160);\n",
    "\n",
    "preds = cc_model.evaluate(X_test, Y_test);\n",
    "print();\n",
    "print (\"Loss = \" + str(preds[0]));\n",
    "print (\"Test Accuracy = \" + str(preds[1]));\n",
    "\n",
    "# serialize model to JSON\n",
    "model_json = cc_model.to_json()\n",
    "with open(\"cc_model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "cc_model.save_weights(\"cc_model.h5\")\n",
    "print(\"Saved model to disk\")\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
